{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f708f343-bba6-4b4a-8a9c-104122a43609",
   "metadata": {},
   "source": [
    "### Problem Statement : **Predict for how long an employee will be absent based on features given in the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdcc864a-f9cd-46d0-b352-02c04dbc3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2ea2fb-0817-4080-9462-1287e7f65259",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"absenteeism_at_work/Absenteeism_at_work.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0169b6-7694-4c84-b978-fe2a62578e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d8e49e-113e-4b57-8133-87ba29fef07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dataset.iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ad78e1-ddaf-430a-a105-803d0ca15ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in dataset.iterrows():\n",
    "    values = row['ID;Reason for absence;Month of absence;Day of the week;Seasons;Transportation expense;Distance from Residence to Work;Service time;Age;Work load Average/day ;Hit target;Disciplinary failure;Education;Son;Social drinker;Social smoker;Pet;Weight;Height;Body mass index;Absenteeism time in hours'].split(';')\n",
    "    dataset.loc[index, 'ID'] = values[0]\n",
    "    dataset.loc[index, 'Reason for absence'] = values[1]\n",
    "    dataset.loc[index, 'Month of absence'] = values[2]\n",
    "    dataset.loc[index, 'Day of the week'] = values[3]\n",
    "    dataset.loc[index, 'Seasons'] = values[4]\n",
    "    dataset.loc[index, 'Transportation expense'] = values[5]\n",
    "    dataset.loc[index, 'Distance from Residence to Work'] = values[6]\n",
    "    dataset.loc[index, 'Service time'] = values[7]\n",
    "    dataset.loc[index, 'Age'] = values[8]\n",
    "    dataset.loc[index, 'Work load Average/day'] = values[9]\n",
    "    dataset.loc[index, 'Hit target'] = values[10]\n",
    "    dataset.loc[index, 'Disciplinary failure'] = values[11]\n",
    "    dataset.loc[index, 'Education'] = values[12]\n",
    "    dataset.loc[index, 'Son'] = values[13]\n",
    "    dataset.loc[index, 'Social drinker'] = values[14]\n",
    "    dataset.loc[index, 'Social smoker'] = values[15]\n",
    "    dataset.loc[index, 'Pet'] = values[16]\n",
    "    dataset.loc[index, 'Weight'] = values[17]\n",
    "    dataset.loc[index, 'Height'] = values[18]\n",
    "    dataset.loc[index, 'Body mass index'] = values[19]\n",
    "    dataset.loc[index, 'Absenteeism time in hours'] = values[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1872a2-03e7-4925-b472-69288e4e3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d68aaf1-f4d4-4d36-9269-d1e326a69989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.drop(columns = 'ID;Reason for absence;Month of absence;Day of the week;Seasons;Transportation expense;Distance from Residence to Work;Service time;Age;Work load Average/day ;Hit target;Disciplinary failure;Education;Son;Social drinker;Social smoker;Pet;Weight;Height;Body mass index;Absenteeism time in hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8490b778-eb38-48a4-ae08-37c71ddc936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d652b1-c725-4372-b273-4f7acfba37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e255d68-866a-4aa1-bd66-aa16b7266a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4fb8b2b-8a20-47ce-8a11-bb9a9b753529",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "1. Individual identification (ID)\n",
    "2. Reason for absence (ICD).\n",
    "Absences attested by the International Code of Diseases (ICD) stratified into 21 categories (I to XXI) as follows:\n",
    "\n",
    "I Certain infectious and parasitic diseases  \n",
    "II Neoplasms  \n",
    "III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism  \n",
    "IV Endocrine, nutritional and metabolic diseases  \n",
    "V Mental and behavioural disorders  \n",
    "VI Diseases of the nervous system  \n",
    "VII Diseases of the eye and adnexa  \n",
    "VIII Diseases of the ear and mastoid process  \n",
    "IX Diseases of the circulatory system  \n",
    "X Diseases of the respiratory system  \n",
    "XI Diseases of the digestive system  \n",
    "XII Diseases of the skin and subcutaneous tissue  \n",
    "XIII Diseases of the musculoskeletal system and connective tissue  \n",
    "XIV Diseases of the genitourinary system  \n",
    "XV Pregnancy, childbirth and the puerperium  \n",
    "XVI Certain conditions originating in the perinatal period  \n",
    "XVII Congenital malformations, deformations and chromosomal abnormalities  \n",
    "XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified  \n",
    "XIX Injury, poisoning and certain other consequences of external causes  \n",
    "XX External causes of morbidity and mortality  \n",
    "XXI Factors influencing health status and contact with health services.\n",
    "\n",
    "And 7 categories without (CID) patient follow-up (22), medical consultation (23), blood donation (24), laboratory examination (25), unjustified absence (26), physiotherapy (27), dental consultation (28).\n",
    "3. Month of absence\n",
    "4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))\n",
    "5. Seasons\n",
    "6. Transportation expense\n",
    "7. Distance from Residence to Work (kilometers)\n",
    "8. Service time\n",
    "9. Age\n",
    "10. Work load Average/day \n",
    "11. Hit target\n",
    "12. Disciplinary failure (yes=1; no=0)\n",
    "13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))\n",
    "14. Son (number of children)\n",
    "15. Social drinker (yes=1; no=0)\n",
    "16. Social smoker (yes=1; no=0)\n",
    "17. Pet (number of pet)\n",
    "18. Weight\n",
    "19. Height\n",
    "20. Body mass index\n",
    "21. Absenteeism time in hours (target)\n",
    "\n",
    ".arff header for Weka: \n",
    "\n",
    "@relation Absenteeism_at_work\n",
    "\n",
    "@attribute ID {31.0, 27.0, 19.0, 30.0, 7.0, 20.0, 24.0, 32.0, 3.0, 33.0, 26.0, 29.0, 18.0, 25.0, 17.0, 14.0, 16.0, 23.0, 2.0, 21.0, 36.0, 15.0, 22.0, 5.0, 12.0, 9.0, 6.0, 34.0, 10.0, 28.0, 13.0, 11.0, 1.0, 4.0, 8.0, 35.0}\n",
    "@attribute Reason_for_absence {17.0, 3.0, 15.0, 4.0, 21.0, 2.0, 9.0, 24.0, 18.0, 1.0, 12.0, 5.0, 16.0, 7.0, 27.0, 25.0, 8.0, 10.0, 26.0, 19.0, 28.0, 6.0, 23.0, 22.0, 13.0, 14.0, 11.0, 0.0}\n",
    "@attribute Month_of_absence REAL\n",
    "@attribute Day_of_the_week {5.0, 2.0, 3.0, 4.0, 6.0}\n",
    "@attribute Seasons {4.0, 1.0, 2.0, 3.0}\n",
    "@attribute Transportation_expense REAL\n",
    "@attribute Distance_from_Residence_to_Work REAL\n",
    "@attribute Service_time INTEGER\n",
    "@attribute Age INTEGER\n",
    "@attribute Work_load_Average/day_ REAL\n",
    "@attribute Hit_target REAL\n",
    "@attribute Disciplinary_failure {1.0, 0.0}\n",
    "@attribute Education REAL\n",
    "@attribute Son REAL\n",
    "@attribute Drinker {1.0, 0.0}\n",
    "@attribute Smoker {1.0, 0.0}\n",
    "@attribute Pet REAL\n",
    "@attribute Weight REAL\n",
    "@attribute Height REAL\n",
    "@attribute Body_mass_index REAL\n",
    "@attribute Absenteeism_time_in_hours REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe919764-3710-4dc9-83bd-2d6eebbfffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = dataset['ID'].astype(float)\n",
    "df['Reason for absence'] = dataset['Reason for absence'].astype(float)\n",
    "df['Day of the week'] = dataset['Day of the week'].astype(float)\n",
    "df['Month of absence'] = dataset['Month of absence'].astype(float)\n",
    "df['Seasons'] = dataset['Seasons'].astype(float)\n",
    "df['Transportation expense'] = dataset['Transportation expense'].astype(float)\n",
    "df['Distance from Residence to Work'] = dataset['Distance from Residence to Work'].astype(float)\n",
    "df['Service time'] = dataset['Service time'].astype(float)\n",
    "df['Age'] = dataset['Age'].astype(int)\n",
    "df['Work load Average/day'] = df['Work load Average/day'].astype(float)\n",
    "df['Hit target'] = dataset['Hit target'].astype(float)\n",
    "df['Disciplinary failure'] = dataset['Disciplinary failure'].astype(float).astype(float)\n",
    "df['Education'] = dataset['Education'].astype(float)\n",
    "df['Son'] = dataset['Son'].astype(float)\n",
    "#dataset['Social drinker']\n",
    "#dataset['Social smoker']\n",
    "df['Pet'] = dataset['Pet'].astype(float)\n",
    "df['Weight'] = dataset['Weight'].astype(float)\n",
    "df['Height'] = dataset['Height'].astype(float)\n",
    "df['Body mass index'] = dataset['Body mass index'].astype(float)\n",
    "df['Absenteeism time in hours'] = dataset['Absenteeism time in hours'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9d21923-2d1f-40ef-8fb9-0ce365a342d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "094c2be5-f75e-491d-9304-d0bd921ce7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Work load Average/day'] = df['Work load Average/day']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb59404d-b6be-4cb9-9271-f6f936855051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ca20fa0-5b0a-4d94-a8a5-ec1ceda22fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Work load Average/day'] = df['Work load Average/day'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee934833-627b-42e9-9464-23fac35fd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fc66be8-4dc3-4626-bb15-3297eb488072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d80597-1e62-4d09-ab3c-56ffffa3fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Social drinker'].nunique())\n",
    "print(df['Social smoker'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d03cf0a5-8863-48a0-94fe-87733802d567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Social drinker'] = np.where(df['Social drinker'] == '1' , 1.0 ,0.0)\n",
    "df['Social smoker'] = np.where(df['Social smoker'] == '1' , 1.0 ,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0378e35-730a-4d2b-97ae-a63f6944f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b70445e-09f1-432e-b432-606014572ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94370a53-9522-43af-8d2f-f556b7546cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a7c1de-076b-4cec-86f7-b5f61d3524ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"absenteeism_at_work_converted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0cfdca5-c51b-4ce5-af2b-18d9ff492182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28c662dc-9a7d-4817-8c49-9607992d5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "727e8426-8eb6-44ed-8618-eebb39413398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5eb66d2b-4165-4c8e-ba48-17ede0403cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "sns.countplot(x='Reason for absence', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd1239f5-c9d5-40af-9faa-3dc289d48f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len(df.columns) // 2 + 1, ncols=2, figsize=(12, 50))\n",
    "for i, col in enumerate(df.columns):\n",
    "    row = i // 2\n",
    "    col_idx = i % 2\n",
    "    sns.histplot(x=df[col], kde=True, ax=axs[row, col_idx])\n",
    "    axs[row, col_idx].set_title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3270d88-6855-465f-89da-6b566788e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "sns.scatterplot(data = df, x = 'Reason for absence', y = 'Month of absence',size = 'Absenteeism time in hours')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f119e05-47b4-44c1-a53e-ba73ff498d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Distance from Residence to Work'], df['Transportation expense'], s=df['Absenteeism time in hours'])\n",
    "plt.xlabel('Distance from Residence to Work')\n",
    "plt.ylabel(\"Transportation expense\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d79c243-c2f8-4ba9-ad85-2968ac5b481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Distance from Residence to Work'], df['Transportation expense'], s=df['Seasons'])\n",
    "plt.xlabel('Distance from Residence to Work')\n",
    "plt.ylabel(\"Transportation expense\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44f56703-a053-4763-88b6-dfc8372b3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Day of the week'], df['Service time'], s=df['Absenteeism time in hours'])\n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel(\"Service time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dce3941-1cde-4ee2-952b-f99ebb3fcffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Service time'], df['Work load Average/day'], s=df['Absenteeism time in hours'])\n",
    "plt.xlabel(\"Service Time\")\n",
    "plt.ylabel('Work load Average/day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3828a0cd-788d-455d-a000-47f06ca7b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Age'], df['Work load Average/day'], s=df['Absenteeism time in hours'])\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel('Work load Average/day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d67d0521-ff01-412d-9f3a-01f34381e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Hit target'], df['Work load Average/day'], s=df['Absenteeism time in hours'])\n",
    "plt.xlabel(\"Hit target\")\n",
    "plt.ylabel('Work load Average/day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d063b7e-08f5-457b-a186-20dfcaf518bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Age'], df['Hit target'], s=df['Absenteeism time in hours'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel(\"Hit target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034568a4-f50d-4906-b7f5-f7f80553bdeb",
   "metadata": {},
   "source": [
    "#### Pair plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0208389-f920-4998-b57b-e422c533156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbfbe810-4164-498e-a8f7-efae71dd9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ae1fc-4051-416d-9c39-02bf10f0ded7",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning on Complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e93aba5-c412-484b-9f00-f09ff5412c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(df.drop(columns = 'Absenteeism time in hours'), df['Absenteeism time in hours'], test_size=0.2, random_state=4)\n",
    "\n",
    "r2_scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'decision_tree': DecisionTreeRegressor(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'extra_trees': ExtraTreesRegressor(),\n",
    "    'gradient_boosting': GradientBoostingRegressor(),\n",
    "    'mlp': MLPRegressor(),\n",
    "    'bagging': BaggingRegressor(),\n",
    "    'adaboost': AdaBoostRegressor(),\n",
    "    'svr': SVR(),\n",
    "    'vote': VotingRegressor(estimators=[\n",
    "    ('ridge', Ridge()),\n",
    "    ('decision_tree', DecisionTreeRegressor()),\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('extra_trees', ExtraTreesRegressor()),\n",
    "    ('gradient_boosting', GradientBoostingRegressor()),\n",
    "    ('mlp', MLPRegressor()),\n",
    "    ('bagging', BaggingRegressor()),\n",
    "    ('adaboost', AdaBoostRegressor()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "}\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val_scores(model_name, model):\n",
    "    print(f\"Running cross-validation for {model_name}...\")\n",
    "    scores_r2 = cross_val_score(model, X_train, Y_train, cv=5, scoring=r2_scorer)\n",
    "    scores_mse = cross_val_score(model, X_train, Y_train, cv=5, scoring=mse_scorer)\n",
    "    print(f\"Cross-validation R2 scores for {model_name}: {scores_r2}\")\n",
    "    print(f\"Cross-validation MSE scores for {model_name}: {scores_mse}\")\n",
    "    print(f\"Average cross-validation R2 score for {model_name}: {scores_r2.mean()}\")\n",
    "    print(f\"Average cross-validation MSE score for {model_name}: {scores_mse.mean()}\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    cross_val_scores(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a299f43-2f07-4121-99e4-3cba2c47ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(df.drop(columns = 'Absenteeism time in hours'), df['Absenteeism time in hours'], test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "r2_scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "param_grid = {\n",
    "    'ridge': {\n",
    "        'alpha': [0.01, 0.1, 1.0],\n",
    "        'solver': ['auto', 'svd'],\n",
    "        'max_iter': [500, 1000]\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'criterion': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'criterion': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'extra_trees': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'criterion': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'gradient_boosting': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'subsample': [0.8, 0.9]\n",
    "    },\n",
    "    'svr': {\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'C': [1e0, 1e2, 1e4],\n",
    "        'epsilon': [0.1, 1.0]\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50, 50), (100, 100)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.001, 0.01],\n",
    "        'max_iter': [500, 1000]\n",
    "    },\n",
    "    'bagging': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_samples': [0.5, 1.0],\n",
    "        'max_features': [0.5, 1.0]\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    'vote':{\n",
    "        'estimators': [100, 500, 1000]\n",
    "    }\n",
    "}\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'decision_tree': DecisionTreeRegressor(),\n",
    "    'extra_trees': ExtraTreesRegressor(),\n",
    "    'gradient_boosting': GradientBoostingRegressor(),\n",
    "    'mlp': MLPRegressor(),\n",
    "    'bagging': BaggingRegressor(),\n",
    "    'adaboost': AdaBoostRegressor(),\n",
    "    'svr': SVR(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'vote': VotingRegressor(estimators=[\n",
    "    ('ridge', Ridge()),\n",
    "    ('decision_tree', DecisionTreeRegressor()),\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('extra_trees', ExtraTreesRegressor()),\n",
    "    ('gradient_boosting', GradientBoostingRegressor()),\n",
    "    ('mlp', MLPRegressor()),\n",
    "    ('bagging', BaggingRegressor()),\n",
    "    ('adaboost', AdaBoostRegressor()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "}\n",
    "\n",
    "def grid_search_model(model_name, model, param_grid):\n",
    "    print(f\"Running GridSearchCV for {model_name}...\")\n",
    "    scoring = {'r2': r2_scorer, 'mse': mse_scorer}\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, refit='r2', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best R2 Score for {model_name}: {grid_search.best_score_}\")\n",
    "    print(f\"Best MSE for {model_name}: {grid_search.cv_results_['mean_test_mse'][grid_search.best_index_]}\")\n",
    "    return grid_search.best_estimator_\n",
    "    \n",
    "best_models = {}\n",
    "for model_name in models:\n",
    "    best_models[model_name] = grid_search_model(model_name, models[model_name], param_grid[model_name])\n",
    "\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    Y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "    mse_val = mse(Y_test, Y_pred)\n",
    "    print(f\"R2 Score for {model_name} on test set: {r2}\")\n",
    "    print(f\"MSE for {model_name} on test set: {mse_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02088f8b-b7c1-4994-9075-b3b20f0bcd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(df.drop(columns = 'Absenteeism time in hours'), df['Absenteeism time in hours'], test_size=0.2, random_state=4)\n",
    "\n",
    "scorer = make_scorer(r2_score)\n",
    "\n",
    "param_grid = {\n",
    "    'ridge': {\n",
    "        'alpha': [0.01, 0.1, 1.0],\n",
    "        'solver': ['auto', 'svd'],\n",
    "        'max_iter': [500, 1000]\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'criterion': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'criterion': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'extra_trees': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'criterion': ['absolute_error', 'squared_error']\n",
    "    },\n",
    "    'gradient_boosting': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'subsample': [0.8, 0.9]\n",
    "    },\n",
    "    'svr': {\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'C': [1e0, 1e2, 1e4],\n",
    "        'epsilon': [0.1, 1.0]\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50, 50), (100, 100)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.001, 0.01],\n",
    "        'max_iter': [500, 1000]\n",
    "    },\n",
    "    'bagging': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_samples': [0.5, 1.0],\n",
    "        'max_features': [0.5, 1.0]\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    'vote':{\n",
    "        'estimators': [100, 500, 1000]\n",
    "    }\n",
    "}\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'decision_tree': DecisionTreeRegressor(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'extra_trees': ExtraTreesRegressor(),\n",
    "    'gradient_boosting': GradientBoostingRegressor(),\n",
    "    'mlp': MLPRegressor(),\n",
    "    'bagging': BaggingRegressor(),\n",
    "    'adaboost': AdaBoostRegressor(),\n",
    "    'svr': SVR(),\n",
    "}\n",
    "\n",
    "def random_search_model(model_name, model, param_distribution):\n",
    "    print(f\"Running RandomizedSearchCV for {model_name}...\")\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distribution, cv=5, n_iter=10, random_state=42, scoring=scorer)\n",
    "    random_search.fit(X_train, Y_train)\n",
    "    print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "    print(f\"Best R2 Score for {model_name}: {random_search.best_score_}\")\n",
    "    return random_search.best_estimator_\n",
    "\n",
    "for model_name in models:\n",
    "    best_models[model_name] = random_search_model(model_name, models[model_name], param_distributions[model_name])\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    Y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "    print(f\"R2 Score for {model_name} on test set: {r2}\")\n",
    "best_model_name = max(best_models, key=lambda x: r2_score(Y_test, best_models[x].predict(X_test)))\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "Y_pred = best_models[best_model_name].predict(X_test)\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f\"R2 Score for best model on test set: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8bb1f3-2b16-4639-b6c2-2e25249e981e",
   "metadata": {},
   "source": [
    "#### PCA Analysis on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363467d-a4f6-42de-86e5-5edf329b0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "# Fit the PCA object to your data and transform it\n",
    "pca_df = pca.fit_transform(df.drop(columns = 'Absenteeism time in hours'))\n",
    "\n",
    "# Convert the transformed data back into a pandas DataFrame\n",
    "pca_df = pd.DataFrame(pca_df, columns=['PC1', 'PC2','PC3','PC4','PC5'])\n",
    "\n",
    "# Print the explained variance ratio for each component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160d3df-a08d-4d63-baba-c320806a9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc1c28-e866-47f1-8a18-6dc6d507da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_df[['PC1', 'PC2', 'PC3']], df['Absenteeism time in hours'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22691a7-073f-44c8-b377-6845ed20cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a 3D scatter plot of the first three principal components\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_df['PC1'], pca_df['PC2'], pca_df['PC3'], c = df['Absenteeism time in hours'])\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "ax.set_title('3D Scatter Plot of First Three Principal Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad4b94-02e0-4405-98ae-a3fee831d26f",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning on PCA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfcdcd-af18-4553-babe-e5f25a4a2c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(df.drop(columns = 'Absenteeism time in hours'), df['Absenteeism time in hours'], test_size=0.2, random_state=4)\n",
    "\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'decision_tree': DecisionTreeRegressor(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'extra_trees': ExtraTreesRegressor(),\n",
    "    'gradient_boosting': GradientBoostingRegressor(),\n",
    "    'mlp': MLPRegressor(),\n",
    "    'bagging': BaggingRegressor(),\n",
    "    'adaboost': AdaBoostRegressor(),\n",
    "    'svr': SVR(),\n",
    "    'vote': VotingRegressor(estimators=[\n",
    "    ('ridge', Ridge()),\n",
    "    ('decision_tree', DecisionTreeRegressor()),\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('extra_trees', ExtraTreesRegressor()),\n",
    "    ('gradient_boosting', GradientBoostingRegressor()),\n",
    "    ('mlp', MLPRegressor()),\n",
    "    ('bagging', BaggingRegressor()),\n",
    "    ('adaboost', AdaBoostRegressor()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "}\n",
    "r2_scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val_scores(model_name, model):\n",
    "    print(f\"Running cross-validation for {model_name}...\")\n",
    "    scores_r2 = cross_val_score(model, X_train, Y_train, cv=5, scoring=r2_scorer)\n",
    "    scores_mse = cross_val_score(model, X_train, Y_train, cv=5, scoring=mse_scorer)\n",
    "    print(f\"Cross-validation R2 scores for {model_name}: {scores_r2}\")\n",
    "    print(f\"Cross-validation MSE scores for {model_name}: {scores_mse}\")\n",
    "    print(f\"Average cross-validation R2 score for {model_name}: {scores_r2.mean()}\")\n",
    "    print(f\"Average cross-validation MSE score for {model_name}: {scores_mse.mean()}\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    cross_val_scores(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5befe8a3-40b9-49ba-9ac4-2b11b3531e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "param_grid = {\n",
    "    'n_components': [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=pca, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(df.drop(columns = 'Absenteeism time in hours'))\n",
    "\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "best_pca = grid_search.best_estimator_\n",
    "best_pca_df = best_pca.fit_transform(df.drop(columns = 'Absenteeism time in hours'))\n",
    "\n",
    "# Use the n_components attribute to determine the number of columns\n",
    "n_components = best_pca.n_components_\n",
    "columns = [f'PC{i+1}' for i in range(n_components)]\n",
    "\n",
    "best_pca_df = pd.DataFrame(best_pca_df, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdb33b-8980-47fd-bb9e-aa72d0708dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "pca = PCA()\n",
    "\n",
    "param_distribution = {\n",
    "    'n_components': [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=pca, param_distributions=param_distribution, cv=5, n_iter=10, random_state=42)\n",
    "random_search.fit(df.drop(columns = 'Absenteeism time in hours'))\n",
    "\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best score:\", random_search.best_score_)\n",
    "\n",
    "best_pca = random_search.best_estimator_\n",
    "\n",
    "best_pca_df = pd.DataFrame(best_pca.fit_transform(df.drop(columns = 'Absenteeism time in hours')), \n",
    "                           columns=[f'PC{i+1}' for i in range(best_pca.n_components_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa337f4-33fd-406c-9e67-1d5f5a50bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "X = df.drop(columns='Absenteeism time in hours')\n",
    "Y = df['Absenteeism time in hours']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Define R2 scorer for RandomizedSearchCV\n",
    "scorer = make_scorer(r2_score)\n",
    "# Define hyperparameter distributions for each model\n",
    "param_distributions = {\n",
    "    'ridge': {\n",
    "        'alpha': [0.05, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0],\n",
    "        'solver': ['svd', 'cholesky']\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'max_depth': [3, 5, 7, 10, 15, 20, 25],\n",
    "        'min_samples_split': [2, 5, 7, 10],\n",
    "        'min_samples_leaf': [1, 2, 4, 5],\n",
    "        'criterion': ['absolute_error', 'poisson', 'squared_error', 'friedman_mse']\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 250, 500, 1000, 2000, 5000, 10000],\n",
    "        'max_depth': [5, 7, 10, 15, 20, 25],\n",
    "        'min_samples_split': [2, 5, 7, 10],\n",
    "        'min_samples_leaf': [1, 2, 4, 5],\n",
    "        'criterion': ['absolute_error', 'poisson', 'squared_error', 'friedman_mse']\n",
    "    },\n",
    "    'extra_trees': {\n",
    "        'n_estimators': [100, 250, 500, 1000, 2000, 5000, 10000],\n",
    "        'max_depth': [5, 7, 10, 15, 20, 25],\n",
    "        'min_samples_split': [2, 5, 7, 10],\n",
    "        'min_samples_leaf': [1, 2, 4, 5],\n",
    "        'criterion': ['absolute_error', 'poisson', 'squared_error', 'friedman_mse']\n",
    "    },\n",
    "    'gradient_boosting': {\n",
    "        'n_estimators': [100, 250, 500, 1000, 2000, 5000, 10000],\n",
    "        'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10, 15, 20, 25],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'svr': {\n",
    "        'kernel': ['poly', 'sigmoid', 'rbf', 'linear'],\n",
    "        'C': [1e0, 1e2, 1e4, 1e6, 1e8, 1e10],\n",
    "        'epsilon': [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50, 50), (100, 100), (200, 200), (500, 500), (1000, 1000)],\n",
    "        'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "    },\n",
    "    'bagging': {\n",
    "        'n_estimators': [100, 250, 500, 1000, 2000, 5000, 10000],\n",
    "        'max_samples': [0.2, 0.5, 0.8, 1.0],\n",
    "        'max_features': [0.2, 0.5, 0.8, 1.0]\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'n_estimators': [100, 250, 500, 1000, 2000, 5000, 10000],\n",
    "        'learning_rate': [0.001, 0.01, 0.05, 0.1]\n",
    "    }\n",
    "}\n",
    "# Define models with their parameter distributions\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'decision_tree': DecisionTreeRegressor(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'extra_trees': ExtraTreesRegressor(),\n",
    "    'gradient_boosting': GradientBoostingRegressor(),\n",
    "    'mlp': MLPRegressor(),\n",
    "    'bagging': BaggingRegressor(),\n",
    "    'adaboost': AdaBoostRegressor(),\n",
    "    'svr': SVR(),\n",
    "}\n",
    "\n",
    "# Function to perform random search and get the best model for each regression\n",
    "def random_search_model(model_name, model, param_distribution):\n",
    "    print(f\"Running RandomizedSearchCV for {model_name}...\")\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distribution, cv=5, n_iter=10, random_state=42, scoring=scorer)\n",
    "    random_search.fit(X_train, Y_train)\n",
    "    print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "    print(f\"Best R2 Score for {model_name}: {random_search.best_score_}\")\n",
    "    return random_search.best_estimator_\n",
    "\n",
    "# Running RandomizedSearchCV for each model\n",
    "best_models = {}\n",
    "for model_name in models:\n",
    "    best_models[model_name] = random_search_model(model_name, models[model_name], param_distributions[model_name])\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "for model_name, model in best_models.items():\n",
    "    Y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "    print(f\"R2 Score for {model_name} on test set: {r2}\")\n",
    "\n",
    "# Compare the performance of the best models\n",
    "best_model_name = max(best_models, key=lambda x: r2_score(Y_test, best_models[x].predict(X_test)))\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Use the best model to make predictions on the test set\n",
    "Y_pred = best_models[best_model_name].predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best model\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f\"R2 Score for best model on test set: {r2}\")\n",
    "\n",
    "# Plot the predicted values against the actual values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel(\"Actual values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217fe4f9-a1af-48a1-a193-c71b5f77f42c",
   "metadata": {},
   "source": [
    "#### Normalization on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe3e99-8c9d-457b-9797-ebd77da623fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df_1 = df.copy()\n",
    "df_1p = df_1.drop(columns = 'Absenteeism time in hours')\n",
    "normalizer = MinMaxScaler()\n",
    "normalized_data = normalizer.fit_transform(df_1p)\n",
    "\n",
    "\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=df_1p.columns)\n",
    "print(\"Standardized Data:\")\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b567e2-c079-453c-bfc1-68ff08461f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df['Absenteeism time in hours'] = df['Absenteeism time in hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c0e2b-94a4-450e-ba02-deb5ad92d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386d980-f2b5-4a52-9780-c1ede629c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(normalized_df.drop(columns = 'Absenteeism time in hours'), normalized_df['Absenteeism time in hours'], test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val_scores(model_name, model):\n",
    "    print(f\"Running cross-validation for {model_name}...\")\n",
    "    scores_r2 = cross_val_score(model, X_train, Y_train, cv=5, scoring=r2_scorer)\n",
    "    scores_mse = cross_val_score(model, X_train, Y_train, cv=5, scoring=mse_scorer)\n",
    "    print(f\"Cross-validation R2 scores for {model_name}: {scores_r2}\")\n",
    "    print(f\"Cross-validation MSE scores for {model_name}: {scores_mse}\")\n",
    "    print(f\"Average cross-validation R2 score for {model_name}: {scores_r2.mean()}\")\n",
    "    print(f\"Average cross-validation MSE score for {model_name}: {scores_mse.mean()}\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    cross_val_scores(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a1aca-a178-40f9-be6e-303c1ccde733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a47fc5-8e9a-4bc3-9cf8-ce4e3540370c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a49311-b5ec-471a-99e2-673fb6738157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lasso = Lasso(alpha=0.01)\n",
    "lasso.fit(X = df.drop(columns = 'Absenteeism time in hours'), y = df['Absenteeism time in hours'])\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "selection = SelectFromModel(lasso, prefit=True)\n",
    "X_selected = selection.transform(df.drop(columns='Absenteeism time in hours'))\n",
    "\n",
    "feature_names = df.drop(columns='Absenteeism time in hours').columns\n",
    "\n",
    "print(\"Selected features:\", feature_names[selection.get_support()])\n",
    "print(\"Coefficients:\", coefficients[selection.get_support()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd073d6-7f97-4155-8407-1c1e2b9f25ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Create a Lasso regression model with a regularization parameter of 0.01\n",
    "lasso = Lasso(alpha=0.01)\n",
    "\n",
    "# Fit the Lasso model to the data\n",
    "lasso.fit(X=df.drop(columns='Absenteeism time in hours'), y=df['Absenteeism time in hours'])\n",
    "\n",
    "# Get the permutation importance of the features\n",
    "importances = permutation_importance(lasso, df.drop(columns='Absenteeism time in hours'), df['Absenteeism time in hours'], n_repeats=10, random_state=42)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature importances:\", importances.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433622a-53bb-4554-91e1-399fea5a9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(importances.importances_mean)), importances.importances_mean)\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238845c7-550a-44a7-99f0-f7e8f2c76710",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df.drop(columns='Absenteeism time in hours').columns\n",
    "\n",
    "top_features_indices = np.argsort(importances.importances_mean)[::-1][:5]\n",
    "top_features = feature_names[top_features_indices]\n",
    "print(\"Top 5 most important features:\", top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f6b7f-fbbf-42e2-a23d-a738811b6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp = df[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e38e186-6469-4f15-90b9-46479757a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804513b6-d315-40a7-bfb3-4e9ab165a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_imp = df['Absenteeism time in hours']\n",
    "Y_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22591b7c-dc3f-48fd-a213-d1a34d084758",
   "metadata": {},
   "source": [
    "#### CV score for top selected features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7494c-3993-471f-9d17-ce9bf616901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X_imp,Y_imp, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val_scores(model_name, model):\n",
    "    print(f\"Running cross-validation for {model_name}...\")\n",
    "    scores_r2 = cross_val_score(model, X_train, Y_train, cv=5, scoring=r2_scorer)\n",
    "    scores_mse = cross_val_score(model, X_train, Y_train, cv=5, scoring=mse_scorer)\n",
    "    print(f\"Cross-validation R2 scores for {model_name}: {scores_r2}\")\n",
    "    print(f\"Cross-validation MSE scores for {model_name}: {scores_mse}\")\n",
    "    print(f\"Average cross-validation R2 score for {model_name}: {scores_r2.mean()}\")\n",
    "    print(f\"Average cross-validation MSE score for {model_name}: {scores_mse.mean()}\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    cross_val_scores(model_name, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195c5d8-6bd1-4952-aac6-a8569db864a3",
   "metadata": {},
   "source": [
    "## Data Restructuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d242e-fd1e-4424-8835-59fe71e1fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "allabsents=df[df['Absenteeism time in hours']!=0]\n",
    "allabsents=allabsents.drop(['Disciplinary failure'],axis=1)\n",
    "len(allabsents.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96ece3-6038-416f-869c-ce3a53c287fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=allabsents.groupby(['ID'])['Hit target'].mean()\n",
    "work=allabsents.groupby(['ID'])['Work load Average/day'].mean()\n",
    "age=allabsents.groupby(['ID'])['Age'].mean()\n",
    "transport=allabsents.groupby(['ID'])['Transportation expense'].mean()\n",
    "height=allabsents.groupby(['ID'])['Height'].mean()\n",
    "service=allabsents.groupby(['ID'])['Service time'].mean()\n",
    "weight=allabsents.groupby(['ID'])['Weight'].mean()\n",
    "body=allabsents.groupby(['ID'])['Body mass index'].mean()\n",
    "hours=allabsents.groupby(['ID'])['Absenteeism time in hours'].sum()\n",
    "drink=allabsents.groupby(['ID'])['Social drinker'].mean()\n",
    "smoker=allabsents.groupby(['ID'])['Social smoker'].mean()\n",
    "education=allabsents.groupby(['ID'])['Education'].mean()\n",
    "pet=allabsents.groupby(['ID'])['Pet'].mean()\n",
    "smoker=allabsents.groupby(['ID'])['Social smoker'].mean()\n",
    "distance=allabsents.groupby(['ID'])['Distance from Residence to Work'].mean()\n",
    "df_optimised=pd.concat([target,work,age,transport,service,height,body,weight,drink,smoker,education,pet,distance,hours],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931e3b8-6c41-4e01-8ce2-edeadd18f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(li):\n",
    "    correlations = li.corr()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,9))\n",
    "    sns.heatmap(correlations, vmax=1.0, center=0, fmt='.2f',\n",
    "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70})\n",
    "    plt.show();\n",
    "    \n",
    "correlation_heatmap(df_optimised[['Age','Weight','Transportation expense' ,'Body mass index','Distance from Residence to Work','Service time','Height','Work load Average/day','Hit target','Absenteeism time in hours']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf429e-1af1-4393-891d-2c750ddb3f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    sns.boxplot(df[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adcda89-78ea-4fc3-9b5c-c510efaee2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "sns.countplot(x='Absenteeism time in hours',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d78281-7352-4d3a-8b92-e89dea2d85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "abt=[]\n",
    "for i in df['Absenteeism time in hours']:\n",
    "    if i<8:\n",
    "        abt.append(0)\n",
    "    else:\n",
    "        abt.append(1)\n",
    "df['newabsent']=abt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd7c38-edea-4e55-9bce-8357ef3a112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bo=[]\n",
    "for i in df['Reason for absence']:\n",
    "    if i<20:\n",
    "        bo.append(1)\n",
    "    else:\n",
    "        bo.append(0)\n",
    "df['newReason']=bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc758cb3-7218-41f8-9e61-61e916656116",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['Age','Service time','Work load Average/day','Hit target','Weight']\n",
    "for i in col:\n",
    "    sns.lineplot(x=i,y='Absenteeism time in hours',hue='newReason',data=df)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c4189-b0ab-431e-aa0e-7b5e58558b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['Body mass index', 'Weight', 'Disciplinary failure','newReason','Age','Service time','Work load Average/day','Hit target']\n",
    "new_df = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855f36c-f668-4d30-96db-c8ea357a9c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca0b41-2ee1-49c7-b031-2ac7b18c403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df\n",
    "y = df['Absenteeism time in hours']\n",
    "\n",
    "print(X.head())\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240acdc8-2f43-4b13-880d-9e444004adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'decision_tree': DecisionTreeRegressor(),\n",
    "    'random_forest': RandomForestRegressor(),\n",
    "    'extra_trees': ExtraTreesRegressor(),\n",
    "    'gradient_boosting': GradientBoostingRegressor(),\n",
    "    'mlp': MLPRegressor(),\n",
    "    'bagging': BaggingRegressor(),\n",
    "    'adaboost': AdaBoostRegressor(),\n",
    "    'svr': SVR(),\n",
    "    'vote': VotingRegressor(estimators=[\n",
    "    ('ridge', Ridge()),\n",
    "    ('decision_tree', DecisionTreeRegressor()),\n",
    "    ('random_forest', RandomForestRegressor()),\n",
    "    ('extra_trees', ExtraTreesRegressor()),\n",
    "    ('gradient_boosting', GradientBoostingRegressor()),\n",
    "    ('mlp', MLPRegressor()),\n",
    "    ('bagging', BaggingRegressor()),\n",
    "    ('adaboost', AdaBoostRegressor()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "}\n",
    "def cross_val_scores(model_name, model):\n",
    "    print(f\"Running cross-validation for {model_name}...\")\n",
    "    scores_r2 = cross_val_score(model, X_train, Y_train, cv=5, scoring=r2_scorer)\n",
    "    scores_mse = cross_val_score(model, X_train, Y_train, cv=5, scoring=mse_scorer)\n",
    "    print(f\"Cross-validation R2 scores for {model_name}: {scores_r2}\")\n",
    "    print(f\"Cross-validation MSE scores for {model_name}: {scores_mse}\")\n",
    "    print(f\"Average cross-validation R2 score for {model_name}: {scores_r2.mean()}\")\n",
    "    print(f\"Average cross-validation MSE score for {model_name}: {scores_mse.mean()}\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    cross_val_scores(model_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b63bce-832b-46df-aba5-85dea52b21e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd11a188-00ef-4b46-aa21-300b372cad32",
   "metadata": {},
   "source": [
    "## **Ridge Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccbb78a-1216-4087-a57e-d88a3b9425cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df[['Body mass index', 'Weight', 'Disciplinary failure','newReason','Age','Service time','Work load Average/day','Hit target']]\n",
    "y = df['Absenteeism time in hours']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ridge_model = Ridge(alpha = 0.5)\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE) of model over Test dataset: \", mse)\n",
    "\n",
    "input_features = [31.0, 98.0, 1.0, 1, 50, 18.0, 239554, 97.0]  \n",
    "input_features = pd.DataFrame([input_features], columns=X.columns)\n",
    "output = ridge_model.predict(input_features)\n",
    "print(\"Output: \", output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcbb4b-d8df-48f2-bb0f-4e61aa175856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1a2bf-12b1-43e0-a91c-a6a348cffdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f826e163-0eee-4281-96d0-9c2207b9e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ridge_model.pkl', 'wb') as f:\n",
    "    pickle.dump(ridge_model, f)\n",
    "\n",
    "print(\"Model saved to ridge_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bf9f9-cc41-4854-8271-710095244c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ridge_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "input_features = []\n",
    "for i in ['Body mass index', 'Weight', 'Disciplinary failure','Reason','Age','Service time','Work load Average/day','Hit target']:\n",
    "    input_features.append(input(i))\n",
    "input_features = pd.DataFrame([input_features], columns=X.columns)\n",
    "output = loaded_model.predict(input_features)\n",
    "print(\"Output: \", output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086c7ef-c6a9-46fc-a356-5fa6230e1fff",
   "metadata": {},
   "source": [
    "# **Model is affected by Spurious Correlation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
